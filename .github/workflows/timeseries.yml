# n+1, n+2, n+3 pairs for a given burst
name: Timeseries

on:
  workflow_dispatch:
    inputs:
      fullBurstID:
        type: string
        required: true
        description: ESA Burst Identifier (RelativeObit, ID, Subswath)
        default: '012_023790_IW1'
      polarization:
        type: choice
        required: true
        description: Polarization
        default: VV
        options: 
          - VV
          - VH
          - HH
      nlooks:
        type: choice
        required: true
        description: Range x Azimuth Looks
        default: 20x4
        options: 
          - 20x4
          - 10x2
          - 5x1

jobs:
  searchASF:
    runs-on: ubuntu-latest
    # Map a step output to a job output
    outputs:
      BURST_IDS: ${{ steps.asf-search.outputs.BURST_IDS }}
      MATRIX: ${{ steps.asf-search.outputs.MATRIX_PARAMS_COMBINATIONS }}
    defaults:
      run:
        shell: bash -el {0}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Install Conda environment with Micromamba
        uses: mamba-org/setup-micromamba@v1
        with:
          cache-environment: true
          environment-file: environment.yml

      # https://words.yuvi.in/post/python-in-github-actions/
      - name: Search ASF for bursts
        id: asf-search
        shell:  bash -el -c "python -u {0}"
        run: | 
          import asf_search as asf
          import json
          import os

          results = asf.search(platform=[asf.PLATFORM.SENTINEL1], 
                               processingLevel=asf.BURST, 
                               polarization="${{ inputs.polarization }}",
                               fullBurstID="${{ inputs.fullBurstID }}")
          print('Results: ', len(results))
          burstIDs = [x.meta['native-id'] for x in results]
          # Oldest First 
          burstIDs.sort()

          # Create Matrix Job Mapping (JSON Array)
          pairs = []
          for r in [0]:
            for s in [1,2,3]:
              pairs.append({'reference': burstIDs[r], 'secondary': burstIDs[r+s]})
          matrixJSON = f'{{"include":{json.dumps(pairs)}}}'

          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            print(f'BURST_IDS={burstIDs}', file=f)
            print(f'MATRIX_PARAMS_COMBINATIONS={matrixJSON}', file=f)

      # - name: Test Burst Output
      #   env:
      #     BURST_IDS: ${{ steps.asf-search.outputs.BURST_IDS }}
      #     MATRIX: ${{ steps.asf-search.outputs.MATRIX_PARAMS_COMBINATIONS }}
      #   run: |
      #     #echo $BURST_IDS
      #     echo $MATRIX

  hyp3-isce2:
    needs: searchASF
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -el {0}
    strategy:
      matrix: ${{ fromJson(needs.searchASF.outputs.MATRIX) }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
            repository: 'ASFHyP3/hyp3-isce2'

      - name: Install Conda environment with Micromamba
        uses: mamba-org/setup-micromamba@v1
        with:
          cache-environment: true
          environment-file: environment.yml

      - name: Development install
        run: pip install -e .

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
            aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws-region: us-west-2

      - name: Get Bucket Prefix
        env:
          REF: ${{ matrix.reference }}
          SEC: ${{ matrix.secondary }} 
          BURST: ${{ inputs.fullBurstID }}
        run: |
          PREFIX=${BURST}/${REF:14:8}_${SEC:14:8}
          echo "PREFIX=${PREFIX}" >> $GITHUB_ENV

      - name: Run Example Workflow
        env: 
            EARTHDATA_USERNAME: ${{ secrets.EARTHDATA_USERNAME }}
            EARTHDATA_PASSWORD: ${{ secrets.EARTHDATA_PASSWORD}}
            ESA_USERNAME: ${{ secrets.ESA_USERNAME }}
            ESA_PASSWORD: ${{ secrets.ESA_PASSWORD}}
        run: |
            python -m hyp3_isce2 ++process insar_tops_burst \
            ${{ matrix.reference }}  \
            ${{ matrix.secondary }}  \
            --looks 20x4 \
            --apply-water-mask False \
      #       --bucket fufiters \
      #       --bucket-prefix $PREFIX

      - name: Create STAC Metadata
        run: |
          # Just install couple extra dependencies for script
          pip install pystac rasterio rio-stac jsonschema
          python scripts/hyp3isce2stac.py
      
      - name: Upload to AWS S3
        run: | 
          aws s3 sync S1_* s3://fufiters/$PREFIX

      # - name: Upload Hyp3 Output
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: ${{ env.PREFIX }}
      #     path: S1*.zip